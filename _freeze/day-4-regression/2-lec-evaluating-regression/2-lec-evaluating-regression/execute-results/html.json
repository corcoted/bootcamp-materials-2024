{
  "hash": "42b45468c87a9b617cf1f5f093cc65c3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Evaluating <br> regression models\"\nsubtitle: \"Day 4\"\nexecute:\n  echo: true\nformat: \n  revealjs:\n    slide-number: true\n    incremental: true\n    theme: [\"../../templates/slides-style.scss\"]\n    logo: https://www.stat.uci.edu/bayes-bats/img/logo.png\n    title-slide-attributes: \n      data-background-image: https://www.stat.uci.edu/bayes-bats/img/logo.png\n      data-background-size: 12%\n      data-background-position: 50% 85%\n---\n\n\n\nNote that examples in this part of the lecture are a simplified version of [Chapter 10 of Bayes Rules! book](https://www.bayesrulesbook.com/chapter-10.html).\n\n\n## Packages\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(bayesrules)\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(bayesplot)\n```\n:::\n\n\n\n##\n\n1. __How fair is the model?__ How was the data collected? By whom and for what purpose? How might the results of the analysis, or the data collection itself, impact individuals and society? What biases or power structures might be baked into this analysis?   \n  \n\n\n2. __How wrong is the model?__  George Box famously said: “All models are wrong, but some are useful.” What’s important to know then is, how wrong is our model? Are our model assumptions reasonable?\n\n\n\n3. __How accurate are the posterior predictive models?__    \n\n\n\n## Checking Model Assumptions\n\n\n$$Y_i | \\beta_0, \\beta_1, \\sigma \\stackrel{ind}{\\sim} N(\\mu_i, \\sigma^2) \\;\\; \\text{ with } \\;\\; \\mu_i = \\beta_0 + \\beta_1 X_i  .$$\n\n1. Conditioned on $X$, the observed __data__ $Y_i$ on case $i$ is _independent_ of the observed data on any other case $j$.\n2. The typical $Y$ outcome can be written as a _linear function_ of $X$, $\\mu = \\beta_0 + \\beta_1 X$.\n3. At any $X$ value, $Y$ __varies normally__ around $\\mu$ with consistent variability $\\sigma$. \n\n\n\n## Independence\n\n\n_When taken alone_, ridership $Y$ is likely correlated over time -- today's ridership likely tells us something about tomorrow's ridership.\nYet much of this correlation, or dependence, can be explained by the time of year and features associated with the time of year -- like temperature $X$.\nThus, knowing the _temperature_ on two subsequent days may very well \"cancel out\" the time correlation in their ridership data.\n\n\n## Linearity and Constant Variance\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2-lec-evaluating-regression_files/figure-revealjs/unnamed-chunk-2-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\nThe relationship between ridership and temperature does appear to be linear. Further, with the slight exception of colder days on which ridership is uniformly small, the variability in ridership does appear to be roughly consistent across the range of temperatures $X$.\n\n## Posterior predictive check\n\nConsider a regression model with response variable $Y$, predictor $X$, and a set of regression parameters $\\theta$. For example, in the model in the previous slides $\\theta = (\\beta_0,\\beta_1,\\sigma)$.  Further, let $\\left\\lbrace \\theta^{(1)}, \\theta^{(2)}, \\ldots, \\theta^{(N)}\\right\\rbrace$ be an $N$-length Markov chain for the posterior model of $\\theta$.\nThen a \"good\" Bayesian model will produce _predictions_ of $Y$ with features similar to the _original_ $Y$ data.  To evaluate whether your model satisfies this goal:\n\n1. At each set of posterior plausible parameters $\\theta^{(i)}$, simulate a sample of $Y$ values from the likelihood model, one corresponding to each $X$ in the original sample of size $n$.  This produces $N$ separate samples of size $n$.\n2. Compare the features of the $N$ simulated $Y$ samples, or a subset of these samples, to those of the original $Y$ data.\n\n##\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbike_model <- stan_glm(rides ~ temp_feel, data = bikes,\n                       family = gaussian,\n                       prior_intercept = normal(5000, 1000),\n                       prior = normal(100, 40), \n                       prior_aux = exponential(0.0008),\n                       chains = 4, iter = 5000*2, seed = 84735, refresh = FALSE)\nbike_model_df <- as.data.frame(bike_model)\n```\n:::\n\n\n\n\n##\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfirst_set <- head(bike_model_df, 1)\nbeta_0 <- first_set$`(Intercept)`\nbeta_1 <- first_set$temp_feel\nsigma  <- first_set$sigma\nset.seed(84735)\none_simulation <- bikes %>% \n  mutate(mu = beta_0 + beta_1 * temp_feel,\n         simulated_rides = rnorm(500, mean = mu, sd = sigma)) %>% \n  select(temp_feel, rides, simulated_rides)\n\nhead(one_simulation, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  temp_feel rides simulated_rides\n1  64.72625   654        4006.356\n2  49.04645  1229        1601.470\n```\n\n\n:::\n:::\n\n\n\n\n##\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(one_simulation, aes(x = simulated_rides)) + \n  geom_density(color = \"lightblue\") + \n  geom_density(aes(x = rides), color = \"darkblue\")\n```\n:::\n\n\n\n\n##\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2-lec-evaluating-regression_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n\nOne posterior simulated dataset of ridership (light blue) along with the actual observed ridership data (dark blue)\n\n##\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Examine 50 of the 20000 simulated samples\npp_check(bike_model, nreps = 50) + \n  xlab(\"rides\")\n```\n\n::: {.cell-output-display}\n![](2-lec-evaluating-regression_files/figure-revealjs/unnamed-chunk-7-1.png){width=960}\n:::\n:::\n\n\n\n\n\n## How accurate are the posterior predictive models?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbikes %>% \n  filter(date == \"2012-10-22\") %>% \n  select(temp_feel, rides)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  temp_feel rides\n1  75.46478  6228\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(84735)\npredict_75 <- bike_model_df %>% \n  mutate(mu = `(Intercept)` + temp_feel*75) %>% \n  mutate(y_new = rnorm(20000, mu, sigma))\n```\n:::\n\n\n\n##\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2-lec-evaluating-regression_files/figure-revealjs/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n\n\n\n##\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict_75 %>% \n  summarize(mean = mean(y_new), error = 6228 - mean(y_new))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     mean   error\n1 3967.04 2260.96\n```\n\n\n:::\n:::\n\n\n\n\n##\n\n__observed value__: $Y$  \n__posterior predictive mean__: $Y'$  \n__predictive error__: $Y - Y'$\n\n##\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict_75 %>% \n  summarize(mean = mean(y_new), error = 6228 - mean(y_new))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     mean   error\n1 3967.04 2260.96\n```\n\n\n:::\n:::\n\n\n\n##\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict_75 %>% \n  summarize(sd = sd(y_new), error = 6228 - mean(y_new),\n            error_scaled = error / sd(y_new))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        sd   error error_scaled\n1 1280.947 2260.96     1.765068\n```\n\n\n:::\n:::\n\n\n\n##\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict_75 %>% \n  summarize(lower_95 = quantile(y_new, 0.025),\n            lower_50 = quantile(y_new, 0.25),\n            upper_50 = quantile(y_new, 0.75),\n            upper_95 = quantile(y_new, 0.975))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  lower_95 lower_50 upper_50 upper_95\n1 1497.287 3096.949 4825.354 6512.323\n```\n\n\n:::\n:::\n\n\n\n##\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(84735)\npredictions <- posterior_predict(bike_model, newdata = bikes)\n\ndim(predictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 20000   500\n```\n\n\n:::\n:::\n\n\n\n##\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nppc_intervals(bikes$rides, yrep = predictions, x = bikes$temp_feel, \n              prob = 0.5, prob_outer = 0.95)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](2-lec-evaluating-regression_files/figure-revealjs/unnamed-chunk-17-1.png){width=960}\n:::\n:::\n\n\n\n\n\n\n##\n\n\nLet $Y_1, Y_2, \\ldots, Y_n$ denote $n$ _observed_ outcomes.  Then each $Y_i$ has a corresponding posterior predictive model with _mean_ $Y_i'$ and _standard deviation_ $\\text{sd}_i$.  We can evaluate the overall posterior predictive model quality by the following measures:\n\n- `mae`    \n    The __median absolute error (MAE)__ measures the _typical_ difference between the observed $Y_i$ and their posterior predictive means $Y_i'$, \n\n    $$\\text{MAE} = \\text{median}|Y_i - Y_i'|.$$\n    \n##\n\n- `mae_scaled`    \n    The __scaled median absolute error__ measures the _typical_ number of standard deviations that the observed $Y_i$ fall from their posterior predictive means $Y_i'$:\n\n    $$\\text{MAE scaled} = \\text{median}\\frac{|Y_i - Y_i'|}{\\text{sd}_i}.$$\n\n- `within_50` and `within_95`    \n    The `within_50` statistic measures the proportion of observed values $Y_i$ that fall within their 50% posterior prediction interval.  The `within_95` statistic is similar, but for 95% posterior prediction intervals.\n\n\n##\n\n \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Posterior predictive summaries\nprediction_summary(bike_model, data = bikes)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       mae mae_scaled within_50 within_95\n1 980.9713  0.7660634      0.43     0.968\n```\n\n\n:::\n:::\n\n\n\n## The k-fold cross validation algorithm\n\n1. __Create folds.__ Let $k$ be some integer from 2 to our original sample size $n$. Split the data into $k$ __folds__, or subsets, of roughly equal size.    \n    \n2. __Train and test the model.__    \n    - _Train_ the model using the first $k - 1$ data folds combined.\n    - _Test_ this model on the $k$th data fold.\n    - Measure the prediction quality (eg: by MAE).\n    \n3. __Repeat.__ Repeat step 2 $k - 1$ times, each time leaving out a different fold for testing.\n    \n4. __Calculate cross-validation estimates.__ Steps 2 and 3 produce $k$ different training models and $k$ corresponding measures of prediction quality. _Average_ these $k$ measures to obtain a single cross-validation estimate of prediction quality.\n    \n##\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(84735)\ncv_procedure <- prediction_summary_cv(\n  data = bikes, model = bike_model, k = 10)\n```\n:::\n\n\n\n##\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncv_procedure$folds\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   fold       mae mae_scaled within_50 within_95\n1     1  989.7734  0.7704922      0.46      0.98\n2     2  966.3411  0.7456938      0.42      1.00\n3     3  950.4733  0.7302055      0.42      0.98\n4     4 1018.4444  0.7912678      0.46      0.98\n5     5 1161.8873  0.9085305      0.36      0.96\n6     6  937.0155  0.7326191      0.46      0.94\n7     7 1270.1706  1.0057705      0.32      0.96\n8     8 1112.3146  0.8604153      0.36      1.00\n9     9 1099.5171  0.8682385      0.40      0.92\n10   10  786.4229  0.6062478      0.56      0.94\n```\n\n\n:::\n:::\n\n\n\n\n##\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncv_procedure$cv\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       mae mae_scaled within_50 within_95\n1 1029.236  0.8019481     0.422     0.966\n```\n\n\n:::\n:::\n\n\n\n##\n\nNote that examples in this part of the lecture are a simplified version of [Chapter 11 of Bayes Rules! book](https://www.bayesrulesbook.com/chapter-11.html).\n\n\n## Data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather_WU <- weather_australia %>% \n  filter(location %in% c(\"Wollongong\", \"Uluru\")) %>%\n  mutate(location = droplevels(as.factor(location))) %>% \n  select(location, windspeed9am, humidity9am, \n    pressure9am, temp9am, temp3pm)\n```\n:::\n\n\n\n. . . \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(weather_WU)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 200\nColumns: 6\n$ location     <fct> Uluru, Uluru, Uluru, Uluru, Uluru, Uluru, Uluru, Uluru, U…\n$ windspeed9am <dbl> 20, 9, 7, 28, 24, 22, 22, 4, 2, 9, 20, 20, 9, 22, 9, 24, …\n$ humidity9am  <int> 23, 71, 15, 29, 10, 32, 43, 57, 64, 40, 28, 30, 95, 47, 7…\n$ pressure9am  <dbl> 1023.3, 1012.9, 1012.3, 1016.0, 1010.5, 1012.2, 1025.7, 1…\n$ temp9am      <dbl> 20.9, 23.4, 24.1, 26.4, 36.7, 25.1, 14.9, 15.9, 24.6, 15.…\n$ temp3pm      <dbl> 29.7, 33.9, 39.7, 34.2, 43.3, 33.5, 24.0, 22.6, 33.2, 24.…\n```\n\n\n:::\n:::\n\n\n\n## \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(weather_WU, aes(x = temp9am, y = temp3pm)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](2-lec-evaluating-regression_files/figure-revealjs/unnamed-chunk-24-1.png){width=960}\n:::\n:::\n\n\n\n## \n\n$\\text{likelihood model:} \\; \\; \\; Y_i | \\beta_0, \\beta_1, \\sigma \\;\\;\\;\\stackrel{ind}{\\sim} N\\left(\\mu_i, \\sigma^2\\right)\\text{ with } \\mu_i = \\beta_0 + \\beta_1X_{i1}$\n\n$\\text{prior models:}$ \n\n$\\beta_0\\sim N(\\ldots, \\ldots )$  \n$\\beta_1\\sim N(\\ldots, \\ldots )$  \n$\\sigma \\sim \\text{Exp}(\\ldots)$\n\n\n## \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather_model_1 <- stan_glm(\n  temp3pm ~ temp9am, \n  data = weather_WU, family = gaussian,\n  prior_intercept = normal(25, 5),\n  prior = normal(0, 2.5, autoscale = TRUE), \n  prior_aux = exponential(1, autoscale = TRUE),\n  chains = 4, iter = 5000*2, seed = 84735, refresh = FALSE)\n```\n:::\n\n\n\n\n\n## \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmcmc_dens_overlay(weather_model_1)\n```\n\n::: {.cell-output-display}\n![](2-lec-evaluating-regression_files/figure-revealjs/unnamed-chunk-26-1.png){width=1440}\n:::\n:::\n\n\n\n## \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior_interval(weather_model_1, prob = 0.80)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  10%      90%\n(Intercept) 2.9498083 5.448752\ntemp9am     0.9802648 1.102423\nsigma       3.8739305 4.409474\n```\n\n\n:::\n:::\n\n\n\n## \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_check(weather_model_1)\n```\n\n::: {.cell-output-display}\n![](2-lec-evaluating-regression_files/figure-revealjs/unnamed-chunk-28-1.png){width=960}\n:::\n:::\n\n\n\n## \n\n\n\n### Considering a categorical predictor\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(weather_WU, aes(x = temp3pm, fill = location)) +\n  geom_density(alpha = 0.5)\n```\n\n::: {.cell-output-display}\n![](2-lec-evaluating-regression_files/figure-revealjs/unnamed-chunk-29-1.png){width=960}\n:::\n:::\n\n\n\n## \n\n\n\n$$X_{i2} = \\begin{cases}\n1 & \\text{ Wollongong} \\\\\n0 & \\text{ otherwise (ie. Uluru)} \\\\\n\\end{cases}$$\n\n## \n\n\n\n$\\text{likelihood model:} \\; \\; \\; Y_i | \\beta_0, \\beta_1, \\sigma \\;\\;\\;\\stackrel{ind}{\\sim} N\\left(\\mu_i, \\sigma^2\\right)\\text{ with } \\mu_i = \\beta_0 + \\beta_1X_{i2}$\n\n$\\text{prior models:}$ \n\n$\\beta_0\\sim N(\\ldots, \\ldots )$  \n$\\beta_1\\sim N(\\ldots, \\ldots )$  \n$\\sigma \\sim \\text{Exp}(\\ldots)$\n\n--\n\nFor Uluru, $X_{i2} = 0$ and the trend in 3pm temperature simplifies to \n\n$$\\beta_0 + \\beta_1 \\cdot 0 = \\beta_0 \\; .$$\nFor Wollongong, $X_{i2} = 1$ and the trend in 3pm temperature is\n\n$$\\beta_0 + \\beta_1 \\cdot 1 = \\beta_0 + \\beta_1 \\; .$$\n\n## Simulating the Posterior\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather_model_2 <- stan_glm(\n  temp3pm ~ location,\n  data = weather_WU, family = gaussian,\n  prior_intercept = normal(25, 5),\n  prior = normal(0, 2.5, autoscale = TRUE), \n  prior_aux = exponential(1, autoscale = TRUE),\n  chains = 4, iter = 5000*2, seed = 84735, refresh = FALSE)\n```\n:::\n\n\n\n\n## \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmcmc_dens_overlay(weather_model_2)\n```\n\n::: {.cell-output-display}\n![](2-lec-evaluating-regression_files/figure-revealjs/unnamed-chunk-31-1.png){width=1440}\n:::\n:::\n\n\n\n## \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Posterior summary statistics\nmodel_summary <- summary(weather_model_2)\nhead(as.data.frame(model_summary), -2) %>% \n  select(mean, \"10%\", \"90%\", Rhat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                         mean       10%       90%      Rhat\n(Intercept)         29.718920  29.01943 30.424971 1.0000536\nlocationWollongong -10.317874 -11.31883 -9.301761 1.0001838\nsigma                5.494874   5.14486  5.857824 0.9999858\n```\n\n\n:::\n:::\n\n\n\n. . . \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nb0 <- model_summary[1,1]\nb1 <- model_summary[2,1]\n```\n:::\n\n\n\n## \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(weather_WU, aes(x = temp3pm, fill = location)) + \n  geom_density(alpha = 0.5) + \n  geom_vline(xintercept = c(b0, b0 + b1), \n    linetype = \"dashed\")\n```\n\n::: {.cell-output-display}\n![](2-lec-evaluating-regression_files/figure-revealjs/unnamed-chunk-34-1.png){width=960}\n:::\n:::\n\n\n\n## \n\n\n\n\n### Two Predictors\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(weather_WU, \n    aes(y = temp3pm, x = temp9am, color = location)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)\n```\n\n::: {.cell-output-display}\n![](2-lec-evaluating-regression_files/figure-revealjs/unnamed-chunk-35-1.png){width=960}\n:::\n:::\n\n\n\n## \n\n\n\n$\\text{likelihood model:}$\n$Y_i | \\beta_0, \\beta_1, \\beta_2 \\sigma \\;\\;\\;\\stackrel{ind}{\\sim} N\\left(\\mu_i, \\sigma^2\\right)\\text{ with } \\mu_i = \\beta_0 + \\beta_1X_{i1} + \\beta_2X_{i2}$\n\n$\\text{prior models:}$ \n\n$\\beta_0\\sim N(m_0, s_0 )$  \n$\\beta_1\\sim N(m_1, s_1 )$  \n$\\beta_2\\sim N(m_2, s_2 )$  \n$\\sigma \\sim \\text{Exp}(l)$\n\n## \n\n \n\nIn _Uluru_, $X_{i2} = 0$ and the trend in the relationship between 3pm and 9am temperature simplifies to\n\n$$\\beta_0 + \\beta_1 X_{i1} + \\beta_2 \\cdot 0 = \\beta_0 + \\beta_1 X_{i1} \\; .$$\n\nIn _Wollongong_, $X_{i2} = 1$ and the trend in the relationship between 3pm and 9am temperature simplifies to\n\n$$\\beta_0 + \\beta_1 X_{i1} + \\beta_2 \\cdot 1 = (\\beta_0 + \\beta_2) + \\beta_1 X_{i1} \\; .$$\n\n## \n\n \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather_model_3 <- stan_glm(temp3pm ~ temp9am + location, \n                            data = weather_WU, \n                            family = gaussian, \n                            chains = 4, \n                            iter = 5000*2, \n                            seed = 84735,\n                            refresh = FALSE)\n```\n:::\n\n\n\n\n## \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather_model_3_df <- as.data.frame(weather_model_3)\nhead(weather_model_3_df, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  (Intercept)   temp9am locationWollongong    sigma\n1    11.21958 0.8988170          -7.932687 2.588490\n2    10.35556 0.9015759          -6.722425 2.559874\n3    10.55716 0.8917270          -6.731531 2.556703\n```\n\n\n:::\n:::\n\n\n\n## \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfirst_50 <- head(weather_model_3_df, 50)\n\nggplot(weather_WU, aes(x = temp9am, y = temp3pm)) + \n  geom_point(size = 0.01) + \n  geom_abline(data = first_50, size = 0.1,\n    aes(intercept = `(Intercept)`, slope = temp9am)) + \n  geom_abline(data = first_50, size = 0.1,\n    aes(intercept = `(Intercept)` + locationWollongong, \n    slope = temp9am), color = \"blue\")\n```\n:::\n\n\n\n## \n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2-lec-evaluating-regression_files/figure-revealjs/unnamed-chunk-39-1.png){width=960}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n## \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulate a set of predictions\nset.seed(84735)\ntemp3pm_prediction <- posterior_predict(\n  weather_model_3, \n  newdata = data.frame(\n    temp9am = c(10, 10), location = c(\"Uluru\", \"Wollongong\")))\n```\n:::\n\n\n\n##  Posterior Predictive Model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshortcut_df <- data.frame(uluru = temp3pm_prediction[,1],\n                          woll = temp3pm_prediction[,2])\nggplot(shortcut_df, aes(x = uluru)) +\n  geom_density() +\n  geom_density(aes(x = woll), color = \"blue\")\n```\n\n::: {.cell-output-display}\n![](2-lec-evaluating-regression_files/figure-revealjs/unnamed-chunk-42-1.png){width=960}\n:::\n:::\n\n\n\n## \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(weather_WU,\n       aes(y = temp3pm, x = humidity9am, color = location)) + \n  geom_point(size = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE)\n```\n\n::: {.cell-output-display}\n![](2-lec-evaluating-regression_files/figure-revealjs/unnamed-chunk-43-1.png){width=960}\n:::\n:::\n\n\n\n## \n\n\n\n$\\text{likelihood model:}$\n$Y_i | \\beta_0, \\beta_1, \\beta_2, \\beta_3 \\sigma \\;\\;\\;\\stackrel{ind}{\\sim} N\\left(\\mu_i, \\sigma^2\\right)\\text{ with }$ \n$\\mu_i = \\beta_0 + \\beta_1X_{i2} + \\beta_2X_{i3} + \\beta_3X_{i2}X_{i3}$\n\n$\\text{prior models:}$ \n\n$\\beta_0\\sim N(m_0, s_0 )$  \n$\\beta_1\\sim N(m_1, s_1 )$  \n$\\beta_2\\sim N(m_2, s_2 )$  \n$\\beta_3\\sim N(m_3, s_3 )$  \n$\\sigma \\sim \\text{Exp}(l)$\n\n## \n\n\n\n\nIn _Uluru_, $X_{2} = 0$ and the trend in the relationship between temperature and humidity simplifies to\n\n$$\\mu = \\beta_0 + \\beta_2 X_{3} \\; .$$\n\nIn _Wollongong_, $X_{2} = 1$ and the trend in the relationship between temperature and humidity simplifies to\n\n$$\\mu = \\beta_0 + \\beta_1 + \\beta_2 X_{3} + \\beta_3 X_{3} = (\\beta_0 + \\beta_1) + (\\beta_2 + \\beta_3) X_3 \\; .$$\n\n## \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninteraction_model <- stan_glm(temp3pm ~ location + humidity9am + \n                                location:humidity9am,\n                              data = weather_WU, \n                              family = gaussian,\n                              chains = 4, \n                              iter = 5000*2, \n                              seed = 84735)\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n## \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_summary <- summary(interaction_model)\nhead(as.data.frame(model_summary), -2) %>%\nselect(`10%`, `50%`, `90%`) %>%\nround(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                   10%     50%     90%\n(Intercept)                     36.439  37.601  38.766\nlocationWollongong             -24.793 -21.857 -18.890\nhumidity9am                     -0.214  -0.190  -0.166\nlocationWollongong:humidity9am   0.198   0.245   0.292\nsigma                            4.194   4.466   4.771\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n## \n\n\n\n$$\\begin{array}{lrl}\n\\text{Uluru:}      & \\mu & =  37.601 - 0.19 \\text{ humidity9am} \\\\\n\\text{Wollongong:} & \\mu & = (37.601 - 21.857) + (-0.19 + 0.245) \\text{ humidity9am}\\\\\n&& = 15.744 + 0.055 \\text{ humidity9am}\\\\\n\\end{array}$$\n\n\n\n\n## Do you need an interaction term?\n\n- __Context.__ \n\n- __Visualizations.__ \n\n- __Hypothesis tests.__ \n\n\n\n## More than two predictors\n\n$\\text{likelihood model:} \\; \\; \\; Y_i | \\beta_0, \\beta_1,\\beta_2,...\\beta_p, \\sigma \\;\\;\\;\\stackrel{ind}{\\sim} N\\left(\\mu_i, \\sigma^2\\right)\\text{ with }$ \n$\\mu_i = \\beta_0 + \\beta_1X_{i1} + \\beta_2X_{i2} + \\ldots +\\beta_pX_{ip}$\n\n$\\text{prior models:}$ \n\n$\\beta_0, \\beta_1,\\beta_2, ...,\\beta_p\\sim N(\\ldots, \\ldots )$  \n \n$\\sigma \\sim \\text{Exp}(\\ldots)$\n\n## \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather_model_4 <- stan_glm(\n  temp3pm ~ .,\n  data = weather_WU, family = gaussian, \n  prior_intercept = normal(25, 5),\n  prior = normal(0, 2.5, autoscale = TRUE), \n  prior_aux = exponential(1, autoscale = TRUE),\n  chains = 4, iter = 5000*2, seed = 84735, refresh = FALSE)\n```\n:::\n\n\n\n\n\n## Model evaluation and comparison\n\n<div align=\"center\">\n\n| Model             | Formula                        |\n|---------|-------|\n| `weather_model_1` | `temp3pm ~ temp9am`            |\n| `weather_model_2` | `temp3pm ~ location`           |\n| `weather_model_3` | `temp3pm ~ temp9am + location` |\n| `weather_model_4` | `temp3pm ~ .`                  |\n\n</div>\n\n## \n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2-lec-evaluating-regression_files/figure-revealjs/unnamed-chunk-49-1.png){width=960}\n:::\n:::\n\n\n\n## \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(84735)\npredictions_1 <- posterior_predict(weather_model_1, \n  newdata = weather_WU)\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Posterior predictive models for weather_model_1\nppc_intervals(weather_WU$temp3pm, \n  yrep = predictions_1, \n  x = weather_WU$temp9am, \n  prob = 0.5, prob_outer = 0.95)\n\n# Posterior predictive models for weather_model_2\nppc_violin_grouped(weather_WU$temp3pm, \n  yrep = predictions_2, \n  group = weather_WU$location,\n  y_draw = \"points\")\n```\n:::\n\n\n\n\n## \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprediction_summary_cv(data = weather_WU, \n                      model = weather_model_1, \n                      k = 10)\n```\n:::\n\n\n\n## \n\n\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|                |      |           |          |          |\n|:---------------|:-----|:----------|:---------|:---------|\n|model           |mae   |mae scaled |within 50 |within 95 |\n|weather model 1 |3.285 |0.79       |0.405     |0.97      |\n|weather model 2 |3.653 |0.661      |0.495     |0.935     |\n|weather model 3 |1.142 |0.483      |0.67      |0.96      |\n|weather model 4 |1.206 |0.522      |0.64      |0.95      |\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}