{
  "hash": "796ef2ed04e1512977f5255d3e61578c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hierarchical Models\"\nsubtitle: \"Day 5\"\nformat: \n  revealjs:\n    slide-number: true\n    incremental: true\n    theme: [\"../../templates/slides-style.scss\"]\n    logo: https://www.stat.uci.edu/bayes-bats/img/logo.png\n    title-slide-attributes: \n      data-background-image: https://www.stat.uci.edu/bayes-bats/img/logo.png\n      data-background-size: 12%\n      data-background-position: 50% 85%\n---\n\n\n\nNote that the example in this lecture is from [Chapter 10.2 of Probability and Bayesian Modeling book](https://bayesball.github.io/BOOK/bayesian-hierarchical-modeling.html#hierarchical-normal-modeling)\n\n# Introduction: Observations in Groups\n\n## Recap: The Normal Model \\& Normal Regression\n\n- When you have continuous outcomes, you can use a normal model:\n\\begin{equation*}\nY_i \\mid \\mu, \\sigma \\overset{i.i.d.}{\\sim} \\textrm{Normal}(\\mu, \\sigma), \\,\\,\\, i = 1, \\cdots, n.\n\\end{equation*}\n\n- When you have predictor variables available, $\\{x_{i1}, \\cdots, x_{ip}\\}$; you can specify an observation specific mean:\n\\begin{equation*}\nY_i \\mid \\mu_i, \\sigma \\overset{ind}{\\sim} \\textrm{Normal}(\\mu_i, \\sigma), \\,\\,\\, i = 1, \\cdots, n,\n\\end{equation*}\nwhere \n\\begin{equation*}\n\\mu_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots, \\beta_p x_{ip}.\n\\end{equation*}\n- Observations are assumed independent.\n\n## When Observations Are Not Necessarily Independent\n\n::: nonincremental\n- Observations can be dependent in several ways\n\n- Observations are nested in groups:\n    - Studentsâ€™ test scores from multiple schools\n    - Ratings of movies of different genres\n    - Ratings of dramas of different schedules\n    - Death rates of hospitals\n:::\n\n::: {.callout-warning icon=false}\n## Discussion question\nCan you think of additional examples of observations in groups?\n:::\n\n::: nonincremental\n- We will focus on a movie rating dataset to explore modeling approaches for dependent data\n:::\n\n# Example: Ratings of Animation Movies\n\n## Ratings of Animation Movies\n\n- Example from [Chapter 10.2 of Probability and Bayesian Modeling book](https://bayesball.github.io/BOOK/bayesian-hierarchical-modeling.html#hierarchical-normal-modeling)\n\n- MovieLens: personalized movie recommendation for users\n\n- In one study, a sample on movie ratings for 8 animation movies released in 2010, total 55 ratings\n\n- Each rating is for a movie completed by a user; some movies have many ratings while others have few\n\n- A natural grouping of these 55 ratings: by movie title\n\n## Plot of Ratings by Title\n\n::: panel-tabset\n## Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nMovieRatings <- read.csv(\"2010_animation_ratings.csv\", header = TRUE, sep = \",\")\n\nMovieRatings %>%\n  mutate(Title = as.character(title),\n         Title = recode(Title,\n                  \"Shrek Forever After (a.k.a. Shrek: The Final Chapter) (2010)\" = \"Shrek Forever\",\n                  \"How to Train Your Dragon (2010)\" = \"Dragon\",\n                  \"Toy Story 3 (2010)\" = \"Toy Story 3\",\n                  \"Tangled (2010)\" = \"Tangled\",\n                  \"Despicable Me (2010)\" = \"Despicable Me\",\n                  \"Legend of the Guardians: The Owls of Ga'Hoole (2010)\" = \"Guardians\",\n                  \"Megamind (2010)\" = \"Megamind\",\n                  \"Batman: Under the Red Hood (2010)\" = \"Batman\")) ->\n           MovieRatings\n```\n:::\n\n\n\n## Plot\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](1-lec-hierarchical_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n:::\n\n\n## Summary Statistics of Ratings by Title\n\n| Movie Title                | Mean |   SD |  N |\n| :------------------------- | ---: | ---: | -: |\n| Batman: Under the Red Hood | 5.00 |      |  1 |\n| Despicable Me              | 3.72 | 0.62 |  9 |\n| How to Train Your Dragon   | 3.41 | 0.86 | 11 |\n| Legend of the Guardians    | 4.00 |      |  1 |\n| Megamind                   | 3.38 | 1.31 |  4 |\n| Shrek Forever After        | 4.00 | 1.32 |  3 |\n| Tangled                    | 4.20 | 0.89 | 10 |\n| Toy Story 3                | 3.81 | 0.96 | 16 |\n\n## Modeling Challenges\n\n- Approach 1 - separate estimates for each movie $j$:\n\\begin{equation*}\nY_{1j}, \\cdots, Y_{n_j j} \\overset{i.i.d.}{\\sim} \\textrm{Normal}(\\mu_j, \\sigma_j)\n\\end{equation*}\n    - No relation among groups; groups with small sample size might suffer (e.g., $n_j = 1$)\n\n- Approach 2 - combined estimates for all $J$ movies:\n\\begin{equation*}\nY_{ij} \\overset{i.i.d.}{\\sim} \\textrm{Normal}(\\mu, \\sigma)\n\\end{equation*}\n    - Differences in groups are ignored\n\n## Potential Solutions\n\n- Something in between - hierarchical/multilevel modeling\n    - Pooling information across groups\n    - Achieved through a two-stage prior\n\n# A Hierarchical Model with Random $\\sigma$\n\n## The Sampling Model\n\n::: nonincremental\n- Without loss of generality, assume a group-specific normal model for movie $j$:\n\\begin{eqnarray}\nY_{ij} \\overset{i.i.d.}{\\sim} \\textrm{Normal}(\\mu_j, \\sigma)\n\\end{eqnarray}\nwhere $i = 1, \\cdots, n_j$ and $n_j$ is the number of observations in group $j$\n\n- Model parameters: $\\{\\mu_1, \\cdots, \\mu_J, \\sigma\\}$\n:::\n\n::: {.callout-warning icon=false}\n## Discussion question\nIs a commonly shared $\\sigma$ reasonable? If not, what can you do?\n:::\n\n## A Two-Stage Prior for $\\{\\mu_1, \\cdots, \\mu_J\\}$: Stage 1\n\n- All movies are animation movies, we could assume that the mean ratings are similar across movies\n\n- First stage: the same normal prior distribution for each mean $\\mu_j$\n\\begin{equation}\n\\mu_j \\mid \\mu, \\tau \\sim \\textrm{Normal}(\\mu, \\tau)\n\\end{equation}\n\n- This prior allows information pooled across movies (groups)\n    - If $\\tau$ is large, the $\\mu_j$'s are very different a priori $\\rightarrow$ modest pooling in parameter estimation\n    - If $\\tau$ is small, the $\\mu_j$'s are very similar a priori $\\rightarrow$ large pooling in parameter estimation\n\n- $\\mu$ and $\\tau$: hyperparameters, and treated random\n\n## A Two-Stage Prior for $\\{\\mu_1, \\cdots, \\mu_J\\}$: Stage 2\n\n- Second stage: weakly informative hyperpriors for hyperparameters\n\\begin{eqnarray}\n\\mu &\\sim& \\textrm{Normal}(3, 1) \\\\\n\\tau &\\sim& \\textrm{Cauchy}(0, 1)\n\\end{eqnarray}\n\n- After posterior inference:\n    - The posterior of $\\mu$ is informative about an average mean rating\n    - The posterior of $\\tau$ is informative about the variation among the $\\mu_j$'s\n    \n## Prior for $\\sigma$ and Graphical Representation\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: nonincremental\n- Weakly informative prior for $\\sigma$:\n\\begin{eqnarray}\n\\sigma &\\sim& \\textrm{Cauchy}(0, 1)\n\\end{eqnarray}\n:::\n\n:::\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](treediagram.png){width=500}\n:::\n:::\n\n\n:::\n:::\n\n::: {.callout-warning icon=false}\n## Discussion question\nDescribe how the graphical representation corresponds to the hierarchical model. What parameters/hyperparameters are shared among what?\n:::\n\n\n# MCMC Estimation and Diagnostics\n\n## Fitting The Model\n\n::: nonincremental\n- Use the `brm()` function with `family = gaussian`\n\n- Use `rating \\~ 1 + 1 | Title` expression for model specification\n:::\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(brms)\nml_fit <- brm(data = MovieRatings, family = gaussian,\n               rating ~ 1 + (1 | Title),\n               prior = c(prior(normal(3, 1), class = Intercept),\n                         prior(cauchy(0, 1), class = sd),\n                         prior(cauchy(0, 1), class = sigma)),\n               iter = 20000, warmup = 10000, thin = 10, chains = 2, \n               seed = 1234)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 2.8e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.28 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:     1 / 20000 [  0%]  (Warmup)\nChain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)\nChain 1: Iteration:  4000 / 20000 [ 20%]  (Warmup)\nChain 1: Iteration:  6000 / 20000 [ 30%]  (Warmup)\nChain 1: Iteration:  8000 / 20000 [ 40%]  (Warmup)\nChain 1: Iteration: 10000 / 20000 [ 50%]  (Warmup)\nChain 1: Iteration: 10001 / 20000 [ 50%]  (Sampling)\nChain 1: Iteration: 12000 / 20000 [ 60%]  (Sampling)\nChain 1: Iteration: 14000 / 20000 [ 70%]  (Sampling)\nChain 1: Iteration: 16000 / 20000 [ 80%]  (Sampling)\nChain 1: Iteration: 18000 / 20000 [ 90%]  (Sampling)\nChain 1: Iteration: 20000 / 20000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.948 seconds (Warm-up)\nChain 1:                0.856 seconds (Sampling)\nChain 1:                1.804 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 2.4e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.24 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:     1 / 20000 [  0%]  (Warmup)\nChain 2: Iteration:  2000 / 20000 [ 10%]  (Warmup)\nChain 2: Iteration:  4000 / 20000 [ 20%]  (Warmup)\nChain 2: Iteration:  6000 / 20000 [ 30%]  (Warmup)\nChain 2: Iteration:  8000 / 20000 [ 40%]  (Warmup)\nChain 2: Iteration: 10000 / 20000 [ 50%]  (Warmup)\nChain 2: Iteration: 10001 / 20000 [ 50%]  (Sampling)\nChain 2: Iteration: 12000 / 20000 [ 60%]  (Sampling)\nChain 2: Iteration: 14000 / 20000 [ 70%]  (Sampling)\nChain 2: Iteration: 16000 / 20000 [ 80%]  (Sampling)\nChain 2: Iteration: 18000 / 20000 [ 90%]  (Sampling)\nChain 2: Iteration: 20000 / 20000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 1.18 seconds (Warm-up)\nChain 2:                1.04 seconds (Sampling)\nChain 2:                2.22 seconds (Total)\nChain 2: \n```\n\n\n:::\n:::\n\n\n\n## Saving Posterior Draws\n\n::: nonincremental\n- Save `post` as a matrix of simulated posterior draws\n\n- The model parameters: $\\{\\mu, \\tau, \\mu_1, \\cdots, \\mu_8, \\sigma\\}$\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npost_ml <- as_draws_df(ml_fit)\nprint(post_ml)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A draws_df: 1000 iterations, 2 chains, and 14 variables\n   b_Intercept sd_Title__Intercept sigma Intercept r_Title[Batman,Intercept]\n1          3.7              0.0644  0.93       3.7                   0.04593\n2          3.7              0.4126  0.86       3.7                   0.67061\n3          3.7              0.3802  1.03       3.7                  -0.23811\n4          3.9              0.1161  0.94       3.9                   0.04902\n5          3.6              0.1908  1.08       3.6                   0.23257\n6          4.0              0.3325  0.92       4.0                   0.54079\n7          3.9              0.0014  1.00       3.9                  -0.00042\n8          3.9              0.0184  1.02       3.9                   0.03311\n9          3.7              0.5909  1.04       3.7                   0.88723\n10         3.7              0.1954  0.77       3.7                   0.18054\n   r_Title[Despicable.Me,Intercept] r_Title[Dragon,Intercept]\n1                           0.04259                   0.02938\n2                           0.10414                  -0.31589\n3                           0.04424                  -0.15605\n4                          -0.14215                   0.00073\n5                           0.04627                  -0.04337\n6                           0.32431                  -0.61113\n7                           0.00014                  -0.00065\n8                          -0.01578                   0.00056\n9                          -0.58335                  -0.19641\n10                         -0.13404                  -0.01942\n   r_Title[Guardians,Intercept]\n1                      -0.05366\n2                       0.24010\n3                      -0.10704\n4                      -0.05933\n5                       0.03255\n6                       0.45353\n7                      -0.00079\n8                      -0.01873\n9                      -0.01825\n10                      0.10952\n# ... with 1990 more draws, and 6 more variables\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n```\n\n\n:::\n:::\n\n\n\n\n## Posterior Plots\n\n::: nonincremental\n- Function `mcmc_areas()` displays a density estimate of the simulated posterior draws with a specified credible interval\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(bayesplot)\nmcmc_areas(post_ml, \n           pars = c(\"b_Intercept\", \"r_Title[Batman,Intercept]\"), \n           prob = 0.95)\n```\n\n::: {.cell-output-display}\n![](1-lec-hierarchical_files/figure-revealjs/unnamed-chunk-7-1.png){fig-align='center' width=288}\n:::\n:::\n\n\n\n## Posterior Plots\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(bayesplot)\nmcmc_areas(post_ml, \n           pars = c(\"b_Intercept\", \n                    \"r_Title[Batman,Intercept]\", \n                    \"r_Title[Despicable.Me,Intercept]\", \n                    \"r_Title[Dragon,Intercept]\",\n                    \"r_Title[Guardians,Intercept]\",\n                    \"r_Title[Megamind,Intercept]\",\n                    \"r_Title[Shrek.Forever,Intercept]\",\n                    \"r_Title[Tangled,Intercept]\",\n                    \"r_Title[Toy.Story.3,Intercept]\"), \n           prob = 0.95)\n```\n\n::: {.cell-output-display}\n![](1-lec-hierarchical_files/figure-revealjs/unnamed-chunk-8-1.png){fig-align='center' width=384}\n:::\n:::\n\n\n\n## Posterior Plots\n\n::: nonincremental\n- Between-group variability $\\tau$ vs within-group variability $\\sigma$\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(bayesplot)\nmcmc_areas(post_ml, \n           pars = c(\"sd_Title__Intercept\", \"sigma\"), \n           prob = 0.95)\n```\n\n::: {.cell-output-display}\n![](1-lec-hierarchical_files/figure-revealjs/unnamed-chunk-9-1.png){fig-align='center' width=288}\n:::\n:::\n\n\n\n## MCMC Diagnostics\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nml_fit <- brm(data = MovieRatings, family = gaussian,\n               rating ~ 1 + (1 | Title),\n               prior = c(prior(normal(3, 1), class = Intercept),\n                         prior(cauchy(0, 1), class = sd),\n                         prior(cauchy(0, 1), class = sigma)),\n               iter = 20000, warmup = 10000, thin = 10, chains = 2, \n               seed = 1234)\n```\n:::\n\n\n\n::: nonincremental\n- `iter`: total number of iterations\n- `warmup`: the number of iterations to be discarded (beginning iterations are not converged)\n- `thin`: the number of draws to thin for saving\n- `chains`: the number of MCMC chains (some diagnostics can only be done for more than one chain)\n:::    \n    \n## MCMC Diagnostics: Traceplot\n\n::: nonincremental\n- Function `mcmc_trace()` displays a traceplot of the simulated posterior draws for each chain\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](1-lec-hierarchical_files/figure-revealjs/unnamed-chunk-11-1.png){fig-align='center' width=288}\n:::\n:::\n\n\n\n## MCMC Diagnostics: Autocorrelation Plot\n\n::: nonincremental\n- Function `mcmc_acf()` displays an autocorrelation plot of the simulated posterior draws\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](1-lec-hierarchical_files/figure-revealjs/unnamed-chunk-12-1.png){fig-align='center' width=288}\n:::\n:::\n\n\n\n# Additional Bayesian Inferential Questions\n\n## Shrinkage/Pooling Effects\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](1-lec-hierarchical_files/figure-revealjs/unnamed-chunk-13-1.png){fig-align='center' width=288}\n:::\n:::\n\n\n\n## Sources of Variability\n\n- Two sources of variability in $Y_{ij}$:\n\\begin{eqnarray*}\nY_{ij} &\\overset{i.i.d.}{\\sim}& \\textrm{Normal}(\\mu_j, \\sigma) \\,\\,\\, \\text{[within-group variability]} \\\\\n\\mu_j &\\sim& \\textrm{Normal}(\\mu, \\tau) \\,\\,\\, \\text{[between-group variability]}\n\\end{eqnarray*}\n\n- To compare these two sources of variability, one can compute the fraction\n\\begin{equation*}\nR = \\frac{\\tau^2}{\\tau^2 + \\sigma^2}\n\\end{equation*}\nfrom the posterior draws of $\\tau$ and $\\sigma$\n\n- If $R \\rightarrow 1$, the higher the between-group variability\n\n## Sources of Variability: Results\n\n::: panel-tabset\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntau_draws <- post_ml$sd_Title__Intercept\nsigma_draws <- post_ml$sigma\nR <- tau_draws^2/(tau_draws^2 + sigma_draws^2)\nquantile(R, c(0.025, 0.975))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        2.5%        97.5% \n0.0001082273 0.3860469120 \n```\n\n\n:::\n:::\n\n\n\n## Plot\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](1-lec-hierarchical_files/figure-revealjs/unnamed-chunk-15-1.png){width=960}\n:::\n:::\n\n\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}