{
  "hash": "85efd77275c16d5d23c054ac139995fd",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Discrete Response Data\"\nsubtitle: \"Day 1\"\nformat: \n  revealjs:\n    slide-number: true\n    incremental: true\n    theme: [\"../../templates/slides-style.scss\"]\n    logo: https://www.stat.uci.edu/bayes-bats/img/logo.png\n    title-slide-attributes: \n      data-background-image: https://www.stat.uci.edu/bayes-bats/img/logo.png\n      data-background-size: 12%\n      data-background-position: 50% 85%\n---\n\n\n\n# {.center}\n\nNote that this lecture is based on [Chapters 3-4 of Bayes Rules! book](https://www.bayesrulesbook.com/chapter-3.html).\n\n\n# The Beta Prior Distribution\n\n## Back to Graduate School Applications\n\nWe have been trying to understand $\\pi$, the acceptance rate of a graduate program in a specific department. Let's make a fresh start to the same problem, expanding beyond three possibilities for $\\pi$. Now we will let $\\pi \\in [0,1]$. \n\n\n## Continuous Probability Models    \n \nLet $\\pi$ be a continuous random variable with pdf $f(\\pi)$.\nThen $f(\\pi)$ has the following properties:    \n\n- $\\int_\\pi f(\\pi)d\\pi = 1$, ie. the area under $f(\\pi)$ is 1\n- $f(\\pi) \\ge 0$\n- $P(a < \\pi < b) = \\int_a^b f(\\pi) d\\pi$ when $a \\le b$\n\nInterpreting $f(\\pi)$:\n\n$f(\\pi)$ can be used to *compare* the plausibility of two different values of $\\pi$.\n\n\n\n## Plotting the Continuous Prior\n\nFor each of the following students' prior ideas for $\\pi$, we plot the pdf of a prior.   \n\n-   Bahar thinks that it is extremely difficult to get into this program.\n\n-   Vish thinks that it is difficult to get into this program. \n\n-   Gabriela does not have any strong opinions whether it is difficult or easy to get into this program. \n\n-   Wei thinks that it is easy to get into this program.\n\n-   Beyoncé thinks that it is extremely easy to get into this program.\n\n\n\n## Bahar's prior\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2-lec-discrete-data_files/figure-revealjs/unnamed-chunk-1-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n-   Note: it's the area under the curve here that represents the probability (the total of which is 1), not the value $f(\\pi)$\n\n## Vish's prior\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2-lec-discrete-data_files/figure-revealjs/unnamed-chunk-2-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n## Gabriela's prior\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2-lec-discrete-data_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n## Wei's prior\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2-lec-discrete-data_files/figure-revealjs/unnamed-chunk-4-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n## Beyoncé's prior\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2-lec-discrete-data_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n## Beta Prior Model\n\nLet $\\pi$ be a random variable which can take any value between 0 and 1, ie. $\\pi \\in [0,1]$.\nThen the variability in $\\pi$ might be well modeled by a Beta model with **shape parameters** $\\alpha > 0$ and $\\beta > 0$: \n\n$$\\pi \\sim \\text{Beta}(\\alpha, \\beta)$$\nThe Beta model is specified by continuous pdf\n\\begin{equation}\nf(\\pi) = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\pi^{\\alpha-1} (1-\\pi)^{\\beta-1} \\;\\; \\text{ for } \\pi \\in [0,1] \n\\end{equation}\n where $\\Gamma(z) = \\int_0^\\infty y^{z-1}e^{-y}dy$ and $\\Gamma(z + 1) = z \\Gamma(z)$.  Fun fact: when $z$ is a positive integer, then $\\Gamma(z)$ simplifies to $\\Gamma(z) = (z-1)!$ \n\n---\n\n## Beta Prior Model\n\n:::: {.columns}\n\n::: {.column width=\"70%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2-lec-discrete-data_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n:::\n\n::: {.column width=\"30%\"}\n\n$\\pi \\sim \\text{Beta}(3, 8)$\n\n$f(\\pi) = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\pi^{\\alpha-1} (1-\\pi)^{\\beta-1}$ \n\n$f(\\pi) = \\frac{\\Gamma(3 + 11)}{\\Gamma(3)\\Gamma(8)} 0.5^{3-1} (1-0.5)^{8-1}$ \n\n$f(\\pi) = \\frac{13!}{2!7!} 0.5^{3-1} (1-0.5)^{8-1}$\n\n$f(\\pi) = 0.703125$\n:::\n\n::::\n\n\n\n\n\n\n\n## Beta Prior Model\n\n$\\pi \\sim \\text{Beta}(3, 8)$\n\n:::: {.columns}\n\n::: {.column width=\"70%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2-lec-discrete-data_files/figure-revealjs/unnamed-chunk-7-1.png){width=960}\n:::\n:::\n\n\n:::\n\n::: {.column width=\"30%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbeta(x = 0.5, \n      shape1 = 3, \n      shape2 = 8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.703125\n```\n\n\n:::\n:::\n\n\n\n:::\n\n::::\n\n\n\n\n## Plotting the Beta Prior\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2-lec-discrete-data_files/figure-revealjs/unnamed-chunk-9-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n## Plotting the Beta Prior with `bayesrules` package\n\nUse the `plot_beta()` function in the `bayesrules` package to try different shape parameters. Example:\n\n::: panel-tabset\n## Code\n\n```\nplot_beta(alpha = 5, beta = 7) \n```\n\n## Plot\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2-lec-discrete-data_files/figure-revealjs/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n\n:::\n\n\n\n## Beta Descriptives\n\n$$E(\\pi) = \\frac{\\alpha}{\\alpha + \\beta}$$\n\n$$\\text{Mode}(\\pi) = \\frac{\\alpha - 1}{\\alpha + \\beta - 2}$$  \n\n$$\\text{Var}(\\pi) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2(\\alpha + \\beta + 1)}$$\n\n\n\n\n## Beta Descriptives with `bayesrules` package\n\nUse the `summarize_beta()` function in the `bayesrules` package to find the mean, mode, and variance of various Beta distributions. Example:\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nsummarize_beta(alpha = 5, beta = 7)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       mean mode        var        sd\n1 0.4166667  0.4 0.01869658 0.1367354\n```\n\n\n:::\n:::\n\n\n\n\n# The Beta-Binomial Model\n\n\n## Graduate Admissions \n\nAn applicant to a small graduate program wants to know $\\pi$, the probability of admission, so they can determine how many programs to which they should apply.  Based on commentary on [The GradCafe](https://www.thegradcafe.com) about similar programs, the applicant thinks that $\\pi$ is likely to be in the range of 0.05 to 0.25. \n\n\n## Plotting the Prior\n\n::: {.callout-warning icon=false}\n## Discussion question\n\nIs this a reasonable prior choice?\n\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n````{.cell-code}\n```{{r fig.align='center', fig.height=4}}\nplot_beta(5, 35) +\n    theme(text = element_text(size=20)) \n```\n````\n\n::: {.cell-output-display}\n![](2-lec-discrete-data_files/figure-revealjs/unnamed-chunk-12-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n## Summarizing the Prior\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nsummarize_beta(5, 35)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   mean      mode         var         sd\n1 0.125 0.1052632 0.002667683 0.05164962\n```\n\n\n:::\n:::\n\n\n\n## Binomial Distribution\n\nThe **binomial distribution** is used to obtain the probability of $Y=y$ \"successes\" from a fixed number of $n$ independent **Bernoulli trials**. \n\nA Bernoulli trial has two possible outcomes:\n\n-   one with probability (called the probability of success) $\\pi$, and \n\n-   the other with probability (called the probability of failure) $1-\\pi$.\n\nThe distribution is $P(Y=y)={n \\choose y}\\pi^y(1-\\pi)^{n-y}$ and has mean $n\\pi$ and variance $n\\pi(1-\\pi)$.\n\n## Posterior for the Beta-Binomial Model {.increased-line}\n\nLet $\\pi \\sim \\text{Beta}(\\alpha, \\beta)$ and $Y|n \\sim \\text{Bin}(n,\\pi)$. \n\n. . . \n\n$f(\\pi|y) \\propto \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\pi^{\\alpha-1} (1-\\pi)^{\\beta-1} {n \\choose y}\\pi^y(1-\\pi)^{n-y}$\n\n. . . \n\n\n$f(\\pi|y) \\propto \\pi^{(\\alpha+y)-1} (1-\\pi)^{(\\beta+n-y)-1}$\n\n. . . \n\n$\\pi|y \\sim \\text{Beta}(\\alpha +y, \\beta+n-y)$\n\n. . . \n\n$f(\\pi|y) = \\frac{\\Gamma(\\alpha+\\beta+n)}{\\Gamma(\\alpha+y)\\Gamma(\\beta+n-y)} \\pi^{(\\alpha+y)-1} (1-\\pi)^{(\\beta+n-y)-1}$\n\n\n\n## Conjugate Prior\n\nWe say that $f(\\pi)$ is a **conjugate prior** for $L(\\pi|y)$ if the posterior, $f(\\pi|y) \\propto f(\\pi)L(\\pi|y)$, is from the same model family as the prior.  \n\nThus, the Beta distribution is a conjugate prior for the Binomial likelihood model because the posterior also follows a Beta distribution.\n\n. . . \n\nNote that in the likelihood, $\\pi$ is raised to the power of the number of successes, and $1-\\pi$ is raised to the power of the number of failures.  The prior has a similar structure, and $\\alpha$ is often interpreted as the approximate prior number of successes, and $\\beta$ is often interpreted as the approximate prior number of failures, with $\\alpha+\\beta$ as the approximate prior sample size.\n\n\n## Graduate Program Admissions\n\nThe applicant decides to collect some data on social media and identifies 50 people  who applied to the program and asks them whether they were accepted or not. It turns out that 25 of them were! What is the posterior distribution of $\\pi$ after having observed this data? \n\n. . . \n\n$\\pi|y \\sim \\text{Beta}(\\alpha +y, \\beta+n-y)$\n\n. . . \n\n$\\pi|y \\sim \\text{Beta}(5 +25, 35+50-25)$\n\n. . . \n\n$\\pi|y \\sim \\text{Beta}(30, 60)$\n\n\n\n\n## Plotting the Posterior\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2-lec-discrete-data_files/figure-revealjs/unnamed-chunk-15-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n\n## Summarizing the Posterior\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n       mean      mode         var         sd\n1 0.3333333 0.3295455 0.002442002 0.04941662\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n## Plot Summary\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2-lec-discrete-data_files/figure-revealjs/unnamed-chunk-18-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n## Balancing Act\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2-lec-discrete-data_files/figure-revealjs/unnamed-chunk-20-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n\n\n## Posterior Descriptives\n\n$\\pi|(Y=y) \\sim \\text{Beta}(\\alpha+y, \\beta+n-y)$\n\n$$E(\\pi | (Y=y)) = \\frac{\\alpha + y}{\\alpha + \\beta + n}$$ \n$$\\text{Mode}(\\pi | (Y=y))  = \\frac{\\alpha + y - 1}{\\alpha + \\beta + n - 2} $$\n$$\\text{Var}(\\pi | (Y=y))   = \\frac{(\\alpha + y)(\\beta + n - y)}{(\\alpha + \\beta + n)^2(\\alpha + \\beta + n + 1)}\\\\$$\n\n\n## Descriptives of the Posterior\n\nWhat are the descriptive measures (expected value, mode, and variance) of the posterior distribution for the admissions example?\n\n. . . \n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n      model alpha beta      mean      mode         var         sd\n1     prior     5   35 0.1250000 0.1052632 0.002667683 0.05164962\n2 posterior    30   60 0.3333333 0.3295455 0.002442002 0.04941662\n```\n\n\n:::\n:::\n\n\n\n\n# Balance in Bayesian Analysis\n\n\n## Bechdel Test\n\n(Example from [bayesrulesbook.com](https://bayesrulesbook.com))\n\nAlison Bechdel’s 1985 comic Dykes to Watch Out For has a strip called [The Rule](https://www.npr.org/templates/story/story.php?storyId=94202522?storyId=94202522), in which a person states that they only go to a movie if it satisfies the\nfollowing three rules:\n\n-   the movie has to have at least two women in it;\n-   these two women talk to each other; and\n-   they talk about something besides a man.\n\nThis test is now used for assessing movies in terms of representation of women. Even though there are three criteria, a movie either fails (does not satisfy one or more criteria) or passes (satisfies all three criteria) the Bechdel test.\n\n\n\n## Different Priors, Different Posteriors\n\nLet $\\pi$ be the the proportion of movies that pass the Bechdel test.\n\nThe table shows three different people with three different priors about $\\pi$.\n\n| Optimist | Clueless | Pessimist |\n|:----:|:----:|:-----:|\n| Beta(14,1) | Beta(1,1) | Beta(5,11) |\n  \n\n\n\n\nNext we plot their priors.\n\n\n\n\n## Priors\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2-lec-discrete-data_files/figure-revealjs/unnamed-chunk-22-1.png){fig-align='center' width=1248}\n:::\n:::\n\n\n\n\n\n## Vocabulary\n\n**Informative prior:** An informative prior reflects specific information about the unknown variable with high certainty (ie. low variability).\n\n\n**Vague (diffuse) prior:** A vague or diffuse prior reflects little specific information about the unknown variable. A flat prior, which assigns equal prior plausibility to all possible values of the variable, is a special case.\n\n\n\n## Data\n\n- `library(bayesrules)` has the `bechdel` data frame. Randomly select 20 movies from this dataset (seed = 84735) to be our data\n\n- Based on the observed data, we will update the posterior for all three people\n\n- We calculate the summary statistics for the prior and the posterior for all three\n\n- We plot the prior, likelihood, and the posterior for all three\n\n- We explain the effect of different priors on the posterior\n\n##\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(bayesrules)\nset.seed(84735)\n```\n:::\n\n\n\n. . . \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbechdel_sample <- sample_n(bechdel, 20)\n```\n:::\n\n\n\n. . . \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncount(bechdel_sample, binary)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  binary     n\n  <chr>  <int>\n1 FAIL      11\n2 PASS       9\n```\n\n\n:::\n:::\n\n\n\n\n\n## The Optimist \n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n      model alpha beta      mean      mode         var         sd\n1     prior    14    1 0.9333333 1.0000000 0.003888889 0.06236096\n2 posterior    23   12 0.6571429 0.6666667 0.006258503 0.07911070\n```\n\n\n:::\n:::\n\n\n\n\n\n## The Optimist \n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2-lec-discrete-data_files/figure-revealjs/unnamed-chunk-27-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n## The Clueless \n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n      model alpha beta      mean mode        var        sd\n1     prior     1    1 0.5000000  NaN 0.08333333 0.2886751\n2 posterior    10   12 0.4545455 0.45 0.01077973 0.1038255\n```\n\n\n:::\n:::\n\n\n\n\n\n## The Clueless \n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2-lec-discrete-data_files/figure-revealjs/unnamed-chunk-29-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n## The Pessimist \n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n      model alpha beta      mean      mode        var         sd\n1     prior     5   11 0.3125000 0.2857143 0.01263787 0.11241827\n2 posterior    14   22 0.3888889 0.3823529 0.00642309 0.08014418\n```\n\n\n:::\n:::\n\n\n\n\n\n## The Pessimist\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2-lec-discrete-data_files/figure-revealjs/unnamed-chunk-31-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n## Comparison \n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2-lec-discrete-data_files/figure-revealjs/unnamed-chunk-32-1.png){fig-align='center' width=1440}\n:::\n:::\n\n\n\n\n\n## Different Data, Different Posteriors\n\nOksana, Omari, and Orlando all share the optimistic Beta(14,1) prior for $\\pi$ but each have access to different data. Oksana reviews movies from 1991. Omari reviews movies from 2000, and Orlando reviews movies from 2013. How will the posterior distribution for each differ?\n\n\n## Oksana's Data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbechdel_1991 <- filter(bechdel, year == 1991)\ncount(bechdel_1991, binary)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  binary     n\n  <chr>  <int>\n1 FAIL       7\n2 PASS       6\n```\n\n\n:::\n\n```{.r .cell-code}\n6/13\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4615385\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Oksana's Analysis\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2-lec-discrete-data_files/figure-revealjs/unnamed-chunk-34-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n## Omari's Data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbechdel_2000 <- filter(bechdel, year == 2000)\ncount(bechdel_2000, binary)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  binary     n\n  <chr>  <int>\n1 FAIL      34\n2 PASS      29\n```\n\n\n:::\n\n```{.r .cell-code}\n29/(34+29)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4603175\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Omari's Analysis\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2-lec-discrete-data_files/figure-revealjs/unnamed-chunk-36-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n## Orlando's Data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbechdel_2013 <- filter(bechdel, year == 2013)\ncount(bechdel_2013, binary)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  binary     n\n  <chr>  <int>\n1 FAIL      53\n2 PASS      46\n```\n\n\n:::\n\n```{.r .cell-code}\n46/(53+46)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4646465\n```\n\n\n:::\n:::\n\n\n\n## Orlando's Analysis\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2-lec-discrete-data_files/figure-revealjs/unnamed-chunk-38-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n\n## Summary\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2-lec-discrete-data_files/figure-revealjs/unnamed-chunk-40-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n# Sequential Updating\n\n## Sequential Analysis \n\nIn a sequential Bayesian analysis, a posterior model is updated incrementally as more data comes in.  With the introduction of each new piece of data, the previous posterior model reflecting our understanding prior to observing this data becomes the new prior model.\n\n\n## Time Travel to the End of 1970\n\nSuppose our prior a movie passes the Bechdel test is an optimistic $\\pi \\sim Beta(14,1)$. Now let's look at the 1970 movies.\n\n. . . \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbechdel %>% \n  filter(year == 1970) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n   year title                          binary\n  <dbl> <chr>                          <chr> \n1  1970 Beyond the Valley of the Dolls PASS  \n```\n\n\n:::\n:::\n\n\n\n\n\n## The Posterior\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarize_beta_binomial(14, 1, y = 1, n = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      model alpha beta      mean mode         var         sd\n1     prior    14    1 0.9333333    1 0.003888889 0.06236096\n2 posterior    15    1 0.9375000    1 0.003446691 0.05870853\n```\n\n\n:::\n:::\n\n\n\n\n\n## At the End of 1971\n\nOur posterior at the end of 1970 becomes our new 1971 prior, incorporating the 1970 data, given by $\\pi \\sim Beta(15,1)$\n\nLet's look at the 1971 movies that have been rated.\n\n. . . \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbechdel %>% \n  filter(year == 1971) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 3\n   year title                                   binary\n  <dbl> <chr>                                   <chr> \n1  1971 Escape from the Planet of the Apes      FAIL  \n2  1971 Shaft                                   FAIL  \n3  1971 Straw Dogs                              FAIL  \n4  1971 The French Connection                   FAIL  \n5  1971 Willy Wonka &amp; the Chocolate Factory FAIL  \n```\n\n\n:::\n:::\n\n\n\n\n## The Posterior\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarize_beta_binomial(15, 1, y = 0, n = 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      model alpha beta      mean      mode         var         sd\n1     prior    15    1 0.9375000 1.0000000 0.003446691 0.05870853\n2 posterior    15    6 0.7142857 0.7368421 0.009276438 0.09631427\n```\n\n\n:::\n:::\n\n\n\n\n\n## At the End of 1972\n\nNew prior incorporating 1971 data: $\\pi \\sim Beta(15,6)$\n\n. . . \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbechdel %>% \n  filter(year == 1972) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n   year title          binary\n  <dbl> <chr>          <chr> \n1  1972 1776           FAIL  \n2  1972 Pink Flamingos PASS  \n3  1972 The Godfather  FAIL  \n```\n\n\n:::\n:::\n\n\n\n\n\n## The Posterior\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarize_beta_binomial(15, 6, y = 1, n = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      model alpha beta      mean      mode         var         sd\n1     prior    15    6 0.7142857 0.7368421 0.009276438 0.09631427\n2 posterior    16    8 0.6666667 0.6818182 0.008888889 0.09428090\n```\n\n\n:::\n:::\n\n\n\n\n\n## Summary\n\n| Time                | Data         | Model       |\n|---------------------|--------------|-------------|\n| before the analysis | NA           | Beta(14,1)  |\n| at the end of 1970  | Y = 1, n = 1 | Beta(15,1)  |\n| at the end of 1971  | Y = 0, n = 5 | Beta(15, 6) |\n| at the end of 1972  | Y = 1, n = 3 | Beta(16,8)  |\n\n\n\n\n\n## Data Order Invariance\n\n| Time                | Data         | Model      |\n|---------------------|--------------|------------|\n| before the analysis | NA           | Beta(14,1) |\n| 1972                | Y = 1, n = 3 | Beta(15,3) |\n| 1971                | Y = 0, n = 5 | Beta(15,8) |\n| 1970                | Y = 1, n = 1 | Beta(16,8) |\n\nAs long as we include the same 3 years, our final conclusion is the same!\n\n\n\n\n## What If We Observe All the Data at Once?\n\n| Time                | Data         | Model      |\n|---------------------|--------------|------------|\n| before the analysis | NA           | Beta(14,1) |\n| 1970  | Y = 1, n = 1 |            |\n|1971  | Y = 0, n = 5 |            |\n|1972  | Y = 1, n = 3 |            |\n| Total               | Y = 2, n = 9 |            |\n\n. . . \n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n      model alpha beta      mean      mode         var         sd\n1     prior    14    1 0.9333333 1.0000000 0.003888889 0.06236096\n2 posterior    16    8 0.6666667 0.6818182 0.008888889 0.09428090\n```\n\n\n:::\n:::\n\n\n\n## Sequential Updating\n\nLet $\\theta$ be any parameter of interest with prior pdf $f(\\theta)$.  Then a **sequential analysis** in which we *first* observe a data point $y_1$ and *then* a second data point $y_2$ will produce the same posterior model of $\\theta$ as if we *first* observed $y_2$ and *then* $y_1$: \n\n$$f(\\theta | y_1,y_2) = f(\\theta|y_2,y_1)\\;.$$\n\nSimilarly, the posterior model is invariant to whether we observe the data *all at once* or *sequentially*.\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}